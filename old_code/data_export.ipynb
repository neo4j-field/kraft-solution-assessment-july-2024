{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Any, Dict, List\n",
    "# from neo4j.debug import watch\n",
    "import json\n",
    "\n",
    "# uncomment below line(s) to get debug logging\n",
    "# watch(\"neo4j\", out=sys.stdout) #Output debug to stdout\n",
    "# watch(\"neo4j\", out=open('debugLogs.txt', 'w')) #Output debug to logfile\n",
    "\n",
    "\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = os.environ.get(\"NEO4J_URI\")\n",
    "user = os.environ.get(\"NEO4J_USERNAME\")\n",
    "password = os.environ.get(\"NEO4J_PASSWORD\")\n",
    "dbname = 'neo4j'\n",
    "\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "uri,\n",
    "auth=(user, password),\n",
    "max_transaction_retry_time=180,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_query = (\n",
    "# 'CALL apoc.export.json.all(null, {stream:true}) '\n",
    "# 'YIELD file, nodes, relationships, properties, data '\n",
    "# 'RETURN file, nodes, relationships, properties, data'\n",
    "# )\n",
    "\n",
    "\n",
    "# with driver.session(database=dbname) as session:\n",
    "#     response = list(session.run(ex_query))\n",
    "#     # Loop through results and do something with them\n",
    "#     for p in response:\n",
    "#         print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "match (n:{node_label})\n",
    "call {{\n",
    "  with n\n",
    "  with n, collect {{match (n)-[r]->() return r}} as relList\n",
    "  with  collect(n) as nodeList, relList\n",
    "  call apoc.export.json.data(nodeList, relList, null, {{stream:true}})\n",
    "  yield data\n",
    "  return data\n",
    "}} in 4 concurrent transactions of 200 rows\n",
    "return data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_query = \"\"\"\n",
    "match (n:{node_label})\n",
    "call {{\n",
    "  with n\n",
    "  with  collect(n) as nodeList\n",
    "  call apoc.export.json.data(nodeList, [], null, {{stream:true}})\n",
    "  yield data\n",
    "  return data\n",
    "}} in 4 concurrent transactions of 200 rows\n",
    "return data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_query = \"\"\"\n",
    "match ()-[r:{rel_type}]->()\n",
    "call {{\n",
    "  with r\n",
    "  with  collect(r) as relList\n",
    "  call apoc.export.json.data([], relList, null, {{stream:true}})\n",
    "  yield data\n",
    "  return data\n",
    "}} in 4 concurrent transactions of 200 rows\n",
    "return data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmatch (n:test)\\ncall {\\n  with n\\n  with n, collect {match (n)-[r]->() return r} as relList\\n  with  collect(n) as nodeList, relList\\n  call apoc.export.json.data(nodeList, relList, null, {stream:true})\\n  yield data\\n  return data\\n} in 4 concurrent transactions of 200 rows\\nreturn data\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.format(node_label=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with driver.session(database=dbname) as session:\n",
    "#     response = session.run(query).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(node_label: str) -> List[Dict[str, Any]]:\n",
    "    print(query.format(node_label=node_label))\n",
    "    with driver.session(database=dbname) as session:\n",
    "        return session.run(query.format(node_label=node_label)).values()\n",
    "    \n",
    "def get_node_data(node_label: str) -> List[Dict[str, Any]]:\n",
    "    print(node_query.format(node_label=node_label))\n",
    "    with driver.session(database=dbname) as session:\n",
    "        return session.run(node_query.format(node_label=node_label)).values()\n",
    "\n",
    "def get_rel_data(rel_type: str) -> List[Dict[str, Any]]:\n",
    "    print(rel_query.format(rel_type=rel_type))\n",
    "    with driver.session(database=dbname) as session:\n",
    "        return session.run(rel_query.format(rel_type=rel_type)).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_as_json_lines_file(data: List[Dict[str, Any]], file_name: str = \"data.json\") -> None:\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item[0], indent=4)+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58056"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_data_as_json_lines_file(response, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"source\", \"ingested_table\", \n",
    "          \"dbt_table_or_consumption_view\", \n",
    "          \"powerbi_workspace\", \n",
    "          \"powerbi_report\", \"powerbi_dashboard\", \"powerbi_dashboard_tile\", \n",
    "          \"powerbi_dataset\", \n",
    "          \"powerbi_table\", \"powerbi_datamart\", \"tableau_table\", \"tableau_dashboard\", \"tableau_workbook\", \n",
    "          \"tableau_sheet\"]\n",
    "\n",
    "rels = [\"ingested_as\", \"has_view\", \"referenced_by\", \"used_in_powerbi_table\", \"present_in\", \"in_dashboard\", \"used_in_tile\", \"used_in\", \"in_workspace\", \"contained_in\", \"visualized_as\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = \"powerbi_dataset\"\n",
    "# data = get_data(node_label=label)\n",
    "# save_data_as_json_lines_file(data, label+\".jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "match (n:source)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:ingested_table)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:dbt_table_or_consumption_view)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:powerbi_workspace)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:powerbi_report)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:powerbi_dashboard)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:powerbi_dashboard_tile)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:powerbi_dataset)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:powerbi_table)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:powerbi_datamart)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:tableau_table)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:tableau_dashboard)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:tableau_workbook)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match (n:tableau_sheet)\n",
      "call {\n",
      "  with n\n",
      "  with  collect(n) as nodeList\n",
      "  call apoc.export.json.data(nodeList, [], null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    data = get_node_data(node_label=label)\n",
    "    save_data_as_json_lines_file(data, \"exports/nodes/\"+label+\".jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "match ()-[r:ingested_as]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:has_view]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:referenced_by]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:used_in_powerbi_table]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:present_in]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:in_dashboard]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:used_in_tile]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:used_in]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:in_workspace]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:contained_in]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n",
      "\n",
      "match ()-[r:visualized_as]->()\n",
      "call {\n",
      "  with r\n",
      "  with  collect(r) as relList\n",
      "  call apoc.export.json.data([], relList, null, {stream:true})\n",
      "  yield data\n",
      "  return data\n",
      "} in 4 concurrent transactions of 200 rows\n",
      "return data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rel in rels:\n",
    "    data = get_rel_data(rel_type=rel)\n",
    "    save_data_as_json_lines_file(data, \"exports/relationships/\"+rel+\".jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
